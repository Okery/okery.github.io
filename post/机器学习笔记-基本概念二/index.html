<!DOCTYPE html>
<html lang="en-us">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		
		
		<meta name="generator" content="Hugo 0.57.2" />
		<title>机器学习笔记-基本概念（二） &middot; LiuHe&#39;s blog</title>
		<link rel="shortcut icon" href="https://okery.github.io/images/favicon.ico">
		<link rel="stylesheet" href="https://okery.github.io/css/style.css">
		<link rel="stylesheet" href="https://okery.github.io/css/highlight.css">

		
		<link rel="stylesheet" href="https://okery.github.io/css/monosocialiconsfont.css">
		

		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='https://okery.github.io/'> <span class="arrow">←</span>Home</a>
	
	<a href='https://okery.github.io/posts'>Archive</a>
	<a href='https://okery.github.io/tags'>Tags</a>
	<a href='https://okery.github.io/about'>About</a>

	

	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        机器学习笔记-基本概念（二）
                    </h1>
                    <h2 class="headline">
                    Sep 18, 2019 14:43
                    · 135 words
                    · 1 minute read
                      <span class="tags">
                      
                      </span>
                    </h2>
                </header>
                
                <section id="post-body">
                    

<p><center> <h1>机器学习笔记</h1> </center></p>

<h3 id="模型选择的原则">模型选择的原则</h3>

<h4 id="误差">误差</h4>

<p>​   是模型的预测输出值与其真实值之间的差异</p>

<h4 id="训练">训练</h4>

<p>​   通过已知的样本数据进行学习，从而得到模型的过程</p>

<h4 id="训练误差">训练误差</h4>

<p>​   模型作用与训练集时的误差</p>

<h4 id="泛化">泛化</h4>

<p>​   有具体的、个别的扩大为一般的，即从特殊到一半，成为泛化。对机器学习的模型来讲，泛化是指模型作用于新的样本数据（非训练集）</p>

<h4 id="泛化误差">泛化误差</h4>

<p>​   模型作用于新的样本数据时的误差</p>

<h4 id="模型容量">模型容量</h4>

<p>​   是指拟合各种模型的能力</p>

<h4 id="过拟合和欠拟合">过拟合和欠拟合</h4>

<p>​   是某个模型在训练集上表现很好，但是在新样本上表现差。模型将训练集的特征学习的太好，导致一些非普遍规律被模型接纳和体现，从而在训练集上表现好，但是对于新样本表现差。反之则成为欠拟合，即模型对训练集的一边性质学习较差，模型作用于训练集时表现不好</p>

<h4 id="模型选择">模型选择</h4>

<p>​   针对某个具体的任务，通常会有多种模型可供选择，对同一个模型也会有多组参数，可以通过分析、评估模型的泛化误差，选择泛化误差最小的模型</p>

<h3 id="模型的评估方法">模型的评估方法</h3>

<h4 id="评估思路">评估思路</h4>

<p>​   通过实验测试，对模型的泛化误差进行评估，选出泛化误差最小的模型。待测数据集全集未知，使用测试集进项泛化测试，测试误差即为泛化误差的近似</p>

<p>​   测试集和训练集尽可能互斥</p>

<p>​   测试集和训练集独立同分布</p>

<h4 id="留出法">留出法</h4>

<p>​   将已知数据集的划分极可能保持数据分布一致性，避免因数据划分过程引入为的偏差</p>

<p>​   数据分割存在多种形式会导致不同的训练集、测试集划分，单次留出法结果往往存在偶然性，其稳定性较差，通常会进行若干次随机划分、重复实验评估取平均值作为评估结果</p>

<p>​   数据集拆成两部分，每部分的规模设置会影响评估结果，测试、训练的比例通常为7：3</p>

<p>​   测试集和训练集分开，缓解了过拟合，但一次划分，评估结果偶然性大，而且数据被拆分后，用户训练、测试的数据更小了</p>

<h4 id="交叉验证法">交叉验证法</h4>

<p>​   将数据集划分k个大小相似的互斥的数据子集，子集数据尽可能保证数据分布的一致性（分层采样），每次从中选取一个数据集作为测试集，其余用作训练集，可以进行k次训练和测试，得到评估均值。该验证方法也称作k折交叉验证。使用不同的划分，重复p次，称作p次k折交叉验证</p>

<h4 id="留一法">留一法</h4>

<p>​   是k折交叉验证的特殊形式，将数据集分成两个，其中一个数据集记录条数为1，作为测试集使用，其余记录作为训练集模型。训练出的模型使用全部诗句集训练得到的模型接近，其评估结果比较准确。缺点是当数据集较大时，训练次数和规模较大。</p>

<p>​   充分利用了所有样本，多次划分，评估结果相对稳定，但是计算比较繁琐，需要进行k次训练和评估</p>

<h4 id="自助法">自助法</h4>

<p>​   是一种产生样本的抽象方法，其实质是有放回的随机抽样。级从已知数据集中随机抽取一条数据，然后将该记录放入测试集同时放回原数据集，继续下一次冲一样，知道测试集中的数据条数满足要求。</p>

<p>​   对总体的理论分布没有要求，但是无放回抽样引入了额外的偏差</p>

<h4 id="几种方法的选择">几种方法的选择</h4>

<p>​   已知数据集数量充足时，通常采用留出法或者k折交叉验证法</p>

<p>​   对于已知数据集较小且难以有效划分训练集/测试集的时候，采用自助法</p>

<p>​   对于已知数据集较小且可以有效划分训练集/测试集的时候，采用留一法</p>

<h3 id="假设检验步骤">假设检验步骤</h3>

<h4 id="1-建立假设">1.建立假设</h4>

<p>​   根据具体的问题，建立假设</p>

<p>​   原假设：搜集证据希望推翻的假设，记作$$H_{0}$$</p>

<p>​   备择假设：搜集证据予以支持的假设，记作$$H_{1}$$</p>

<p>​   假设的形式：</p>

<p>​   双尾假设：$$H<em>{0}:\mu=\mu</em>{0},H<em>{1}:\mu\neq\mu</em>{0}$$   不等于，有差异</p>

<p>​   左侧单尾检验：$$H<em>{0}:\mu\geqslant\mu</em>{0},H<em>{1}:\mu&lt;\mu</em>{0}$$  降低，减少</p>

<p>​   右侧单尾检验：$$H<em>{0}:\mu\leq\mu</em>{0},H<em>{1}:\mu&gt;\mu</em>{0}$$  提高，增加</p>

<h4 id="2-确定检验水准">2.确定检验水准</h4>

<p>​   检验水准：又成显著性水平，记作α，是指原假设正确，但是最终被拒绝的概率。在做检验的过程中，会犯两种错误：</p>

<h5 id="原假设为真-被拒绝-称作第一类错误-其概率记作α-即为显著性水平-取值通常为0-0-5-0-025-0-01等">原假设为真，被拒绝，称作第一类错误，其概率记作α，即为显著性水平，取值通常为0.0 5、0.025、0.01等</h5>

<p>​   原假设为假，被接受，称作第二类错误，其概率记作β，即为检验功效</p>

<p>​   显著水平α=0.05的意思是：在原假设正确的情况下进行100次抽样，有5次错误的拒绝了原假设。</p>

<h4 id="3-构造统计量">3.构造统计量</h4>

<p>​   根据资料类型、研究设计方案和统计推断的目的，选用适当检验方法和计算相应的统计量。</p>

<p>​   常见检验方法：</p>

<p>​   t检验：小样本（&lt;30）,总体标准差未知的正态分布</p>

<p>​   F检验：即方差分析，检验两个正态随机变量的总体方差是否相等的一种检验假设方法</p>

<p>​   Z检验：大样本（&gt;=30）平均值差异性检测，又称u检验</p>

<p>​   $$X^{2}$$检验：即卡方检验，用于非参数检验，主要是比较两个及两个以上样本率以及两个分类变量的关联性分析</p>

<h4 id="4-计算p值">4.计算p值</h4>

<p>​   p值用来判定假设检验结果的参数，和显著性水平α相比</p>

<p>​   在原假设为真的前提下出现观察样本以及更极端情况的概率</p>

<p>​   如果p值很小，说明原假设出现的概率很小，应该拒绝，p值越小，拒绝原假设的理由越充足</p>

<h4 id="5-得出结论">5.得出结论</h4>

<p>​   如果p值小于等于显著水平α，表明x小概率时间发生，拒绝原假设</p>

<p>​   统计量的值如果落在拒绝域或者临界值，则拒绝原假设，落在接受域则不能拒绝原假设</p>

<h3 id="偏差">偏差</h3>

<p>​   描述的是根据样本拟合出的模型的输出预测结果的期望与样本真实结果的差距，即在样本上拟合的好不好</p>

<p>​   度量了学习算法的期望预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力</p>

<p>​   体现的是最终结果和实际结果的差异，偏差越小，和真实结果越接近</p>

<h3 id="方差">方差</h3>

<p>​   模型每一次输出结果与模型输出期望之间的差值，即模型的稳定性</p>

<p>​   度量了同样的大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响</p>

<p>​   体现的是整体水平波动，方差越小，结果稳定性越好</p>

<h3 id="噪声">噪声</h3>

<p>​   为真实标记与数据集中的实际标记间的差距。通常由多种因素综合影响造成，不可去除</p>

<p>​   表达了当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度</p>

                </section>
            </article>

            

            

            

            <footer id="footer">
    
    <p class="small">
    
       © Copyright 2019 <i class="fa fa-heart" aria-hidden="true"></i> 
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

        </section>

        <script src="https://okery.github.io/js/jquery-3.3.1.min.js"></script>
<script src="https://okery.github.io/js/main.js"></script>
<script src="https://okery.github.io/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>







    </body>
</html>
