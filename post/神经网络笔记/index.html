<!DOCTYPE html>
<html lang="en-us">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		
		
		<meta name="generator" content="Hugo 0.57.2" />
		<title>神经网络笔记-神经网络基础 &middot; LiuHe&#39;s blog</title>
		<link rel="shortcut icon" href="https://okery.github.io/images/favicon.ico">
		<link rel="stylesheet" href="https://okery.github.io/css/style.css">
		<link rel="stylesheet" href="https://okery.github.io/css/highlight.css">

		
		<link rel="stylesheet" href="https://okery.github.io/css/monosocialiconsfont.css">
		

		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='https://okery.github.io/'> <span class="arrow">←</span>Home</a>
	
	<a href='https://okery.github.io/posts'>Archive</a>
	<a href='https://okery.github.io/tags'>Tags</a>
	<a href='https://okery.github.io/about'>About</a>

	

	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        神经网络笔记-神经网络基础
                    </h1>
                    <h2 class="headline">
                    Oct 7, 2019 10:20
                    · 85 words
                    · 1 minute read
                      <span class="tags">
                      
                      </span>
                    </h2>
                </header>
                
                <section id="post-body">
                    

<p>### 神经元模型</p>

<p>神经元是脑组织的基本单位，是神经系统结构与功能的单位。</p>

<h3 id="m-p模型">M-P模型</h3>

<p>M-P模型通过对生物神经元信息处理过程进行了简化和概括</p>

<ul>
<li>多个输入单个输出</li>
<li>不同输入权重不同</li>
<li>多输入累加整合</li>
<li>阈值特征</li>
</ul>

<p>模型是把神经元是为二值开关元件，按照不同方式组合来完成各种逻辑运算。能够构成逻辑与、非、或，理论上可以进而组成任意复杂的逻辑关系，若将M-P模型按一定方式组织起来，可以构成具有逻辑功能的神经网络</p>

<p>​                   $$net<em>{j}=\sum</em>{i=1}^{n}w<em>{ij}x</em>{i}$$</p>

<p>$$net_{j}$$为累加代数和</p>

<p>​                   $$o<em>{j}=f(net</em>{j}-T<em>{j})=f(\sum</em>{i=1}^{n}w<em>{ij}-T</em>{j})$$</p>

<p>$$T_{j}$$为阈值</p>

<h3 id="激活函数">激活函数</h3>

<p>也叫连接函数、传递函数、变换函数或者激励函数。用来模拟神经元输出与其激活状态之间的联系：输入达到某个阈值后达到激活状态，否则为抑制肽。不同的激活函数，会使神经元具有不同的信息处理特性。对于神经网络来讲，激活函数的主要作用就是进行线性变换，增加系统的非线性表达函数</p>

<h3 id="常见激活函数">常见激活函数</h3>

<p>Sign函数：$$f(x)=sgn(x)$$</p>

<p>sigmoid函数：$$f(x)=\frac{1}{1+e^{-x}}$$(单极性S函数)</p>

<p>Tanh函数：$$f(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$$(双极性S函数)</p>

<p>Arctan函数：$$f(x)=arctan(x)$$</p>

<h3 id="神经网络模型分类">神经网络模型分类</h3>

<h4 id="按照拓扑结果可分为层次结果和互连结构">按照拓扑结果可分为层次结果和互连结构</h4>

<h4 id="层次结构">层次结构</h4>

<ul>
<li>单纯层次结构</li>
<li>层内有互连</li>
<li>输出层到输入层有连接</li>
</ul>

<h4 id="互连结构">互连结构</h4>

<ul>
<li>全互联：每个节点和其他所有节点连接</li>
<li>局部互联：每个节点只与其邻近节点有连接</li>
<li>稀疏连接：节点只与少数相距较远的节点有连接</li>
</ul>

<h4 id="按照信息流量可分为前馈性网络和反馈型网络">按照信息流量可分为前馈性网络和反馈型网络</h4>

<h4 id="前馈型网络">前馈型网络</h4>

<p>网络信息从输入层到各隐藏层再到输出层逐层前进</p>

<p>采用单项多层结构，各神经元分层排列，每个神经元只与前一层的神经元项链。接收前一层的输出，并输出给下一层，各层间没有反馈。</p>

<p>包含三类节点</p>

<ul>
<li>输入节点：外界信息输入，不进行任何计算，仅向下一层节点传递信息，此层必须有</li>
<li>隐藏节点：接受上一层节点的输入，进行结算，并将信息传到下一层节点，此层可以没有，没有即为单层感知器</li>
<li>输出节点：接收上一层节点的输入，进行计算，并将结果输出，此层必须有</li>
</ul>

<p>#### 反馈型网络</p>

<p>反馈网络中所有节点都具有信息处理能力，并且每个节点既可以接受输入同时又可以进行输出</p>

<h3 id="神经网络学习规则">神经网络学习规则</h3>

<h4 id="有监督学习-学习模式为纠错">有监督学习：学习模式为纠错</h4>

<h4 id="无监督学习-学习模式为自组织">无监督学习：学习模式为自组织</h4>

<h4 id="灌输式学习-学习模式为死记硬背">灌输式学习：学习模式为死记硬背</h4>

<h3 id="赫布学习规则">赫布学习规则</h3>

<p>赫布学习规则为前馈、无导师学习。只根据实际输入和输出调整权重</p>

<p>在赫布学习规则中，学习信号简单的等于神经元的输出：$$r=f(W_{j}^{T}X)$$</p>

<p>权值向量的调整公式为：$$\Delta W<em>{j}=\eta f(W</em>{j}^{T}X)X, \eta 为常数$$</p>

<p>权向量各个分量调整为：$$\Delta w<em>{ij}=\eta f(W</em>{j}^{T}X)x<em>{i}=\eta o</em>{j}x_{j},i=0,1,&hellip;,n$$</p>

<p>赫布学习规则的步骤：</p>

<ul>
<li>初始化权值参数W，一般赋予0附近的随机数</li>
<li>初始化学习率η</li>
<li>对所有输入记录：根据输入记录，更新权重值</li>
</ul>

<h3 id="离散感知器学习规则">离散感知器学习规则</h3>

<p>感知器是具有单层神经计算单元的神经网络结构。实际上为一种前馈网络，同层内五互联，不同层间无反馈，由下层向上层传递，其输入、输出均为离散值，神经元对输入加权求和后，由阈值函数决定其输出</p>

<p>离散感知器学习规则代表一种有导师的学习方式，其规定将神经元期望输出与实际输出之差作为学习信号，通过训练调整权值，知道实际输出满足要求</p>

<p>在该学习规则中，学习信号等于神经元的期望输出与实际输出之差：$$r=d<em>{j}-o</em>{j}=d<em>{j}-f(W</em>{j}^{T}X)$$</p>

<p>权值调整公式为$$\Delta W<em>{j}=\eta rX=\eta (d</em>{j}-o<em>{j})X=\eta [d</em>{j}-f(W_{j}^{T}X)]X$$</p>

<p>权向量各分量调整为：$$\Delta w<em>{ij}=\eta [d</em>{j}-f(W<em>{j}^{T}X)]x</em>{i}=\eta (d<em>{j}-o</em>{j})x_{i}, i=0,1,&hellip;,n$$</p>

<p>离散感知器学习规则的步骤：</p>

<ul>
<li>初始化权值参数W，学习率η</li>
<li>对每个样本，实际输出和期望输出的差满足要求：根据输入记录，更新权重值</li>
</ul>

<h3 id="连续感知器学习规则">连续感知器学习规则</h3>

<p>Delta学习规则，一种简单的有导师学习算法，该算法根据神经元的实际输出与期望输出差别来调整连接权。</p>

<p>Delta学习规则的思路：</p>

<p>系统首先用一个输入向量，输入网络结构，得到一个输出向量；每个输入向量都有一个对应的期望输出向量、或者称作是目标向量；比较实际输出向量与期望输出向量的差别，若没有差别，就不再继续学习；否则，连接的权重修改对应的差值</p>

                </section>
            </article>

            

            

            

            <footer id="footer">
    
    <p class="small">
    
       © Copyright 2019 <i class="fa fa-heart" aria-hidden="true"></i> 
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

        </section>

        <script src="https://okery.github.io/js/jquery-3.3.1.min.js"></script>
<script src="https://okery.github.io/js/main.js"></script>
<script src="https://okery.github.io/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>







    </body>
</html>
